'use strict';

/***
	A class to interact with the browser and configure audio-related UI elements
	like source/sink selectors, players, and drop targets.
*/
class audioUI {

	constructor() {

		for (const method of Object.getOwnPropertyNames(Object.getPrototypeOf(this))) {
			if ('constructor' !== method) this[method] = this[method].bind(this);
		}

		window.addEventListener("click", () => {
			const ctx = this.getAudioCtx();
			console.log(`Resuming audioContext (current state: ${ctx.state})`);
			ctx.resume();
		}, { once: true });

	}

	getAudioCtx() {
		if (!this._audioCtx) this._audioCtx = new(window.AudioContext || window.webkitAudioContext)();
		return this._audioCtx;
	}

	// Attempt to ascertain the ability of the browser to enumerate available
	// audio devices, net of any permissions.  init() can be called multiple times
	// if we think the access permissions granted by the user have changed.
	//
	//	no devices at all => selection is not supported (e.g. Safari)
	//		* 0 == this.selectList.length
	//
	//	device exists, but deviceid value is null => not enabled
	//		* "" == this.selectList[0].deviceId
	//		-- try calling getUserMedia() before accessing a selector
	//
	//	at least one entry where deviceid is not null => enabled
	//		* "" != this.selectList[0].deviceId
	async init() {

		this.DEFAULT_NAME = {
			audiooutput: "Default Audio Output",
			audioinput: "Default Audio Input",
			videoinput: "Default Camera"
		};

		this.selectList = {
			audiooutput: [],
			audioinput: [],
			videoinput: []
		}

		this.sourceSelectionEnabled = ('setSinkId' in HTMLMediaElement.prototype);

		const deviceInfos = await navigator.mediaDevices.enumerateDevices();
		for (const deviceInfo of deviceInfos) {
			const option = document.createElement('option');
			option.value = deviceInfo.deviceId;
			option.text = deviceInfo.label.replace(/\([0-9a-fA-F]{4}:[0-9a-fA-F]{4}\)$/, "");

			if (this.selectList.hasOwnProperty(deviceInfo.kind)) {
				if ('' == option.text) option.text = this.DEFAULT_NAME[deviceInfo.kind];
				this.selectList[deviceInfo.kind].push(option);
			}
		}
	}

	// Configures a HTML <audio> element as an audio stream source for WebAudio and WebRTC.
	// This enables multiple destinations for stream output and local monitoring.
	//
	// The following properties are added to the object:
	//		.source = a MediaElementSourceNode representing the output from the player.
	//		.stream =  a MediaStream object representing the output from the player,
	//					which can be passed as input to another player or to WebRTC
	//
	// player.sinkId becomes irrelevant; all audio generated by the player is routed
	// to the output stream.
	configurePlayer(player) {

		if (!player.source) {

			// Grab the output from the player as a MediaElementAudioSourceNode
			// This overrides the effect of player.setSinkId()
			player.source = this.getAudioCtx().createMediaElementSource(player);

			// Expose the output as a MediaStream
			const dest = this.getAudioCtx().createMediaStreamDestination();
			player.source.connect(dest);
			player.stream = dest.stream;
		}
	}

	// Add "monitor" functionality to an <audio> element
	// 	Player = Audio() output to be monitored
	//	ckMonitor = checkbox element controlling monitor on/off
	//	monitorOutputSelector = selector controlling output destination of
	//		monitor stream (typically the destination for general audio output)
	//	playerOutputSelector = selector controlling targeted output destination
	//		of player.
	addMonitor(player, ckMonitor, monitorOutputSelector, playerOutputSelector) {

		// If audio output is not selectable, monitoring is irrelevant because
		// all audio output goes to the same place.
		// Hide the checkbox control and its containing label.
		if ((this.selectList.audiooutput.length <= 1) && !player.source) {
			ckMonitor.parentElement.hidden = true;
			return;
		}

		ckMonitor.addEventListener('change', () => { this.monitor(player, ckMonitor.checked) });

		if (this.selectList.audiooutput.length > 1) {

			monitorOutputSelector.addEventListener('change', async function () {
				// console.log('Monitor aware of changed MONITOR output selection.');
				if (player.monitor) {
					audioUI.tryEnableMonitor(ckMonitor, monitorOutputSelector, playerOutputSelector);
					await player.monitor.setSinkId(monitorOutputSelector.getValue());
				}
			});

			if (playerOutputSelector) {
				playerOutputSelector.addEventListener('change', () => {
					// console.log('Monitor aware of changed PLAYER output selection.');
					audioUI.tryEnableMonitor(ckMonitor, monitorOutputSelector, playerOutputSelector);
				});
			}

			player.monitorOutput = monitorOutputSelector;
		}

		ckMonitor.parentElement.hidden = false;
	}

	// Enable or disable monitoring and the monitor checkbox depending on
	// the settings of the two selectors.  If they are the same, monitoring
	// must be turned off and the checkbox disabled.  If they are different,
	// monitoring can be enabled.
	static tryEnableMonitor(ckMonitor, selector1, selector2) {
		if (selector1 && selector2) {
			if (selector1.getValue() == selector2.getValue()) {
				ckMonitor.checked = false;
				ckMonitor.disabled = true;
				ckMonitor.dispatchEvent(new Event('change'));
			} else {
				ckMonitor.disabled = false;
			}
		}
	}

	// "Monitor" player output by routing it to a local audio channel.
	// Or, turn off monitoring so the
	// audio only plays to the streams configured elsewhere.
	//
	//	This function should only be called as an event handler configured by
	//	the addMonitor function.
	async monitor(player, enable) {

		console.log(`Monitor: enable = ${enable}.  player.monitorOutput = ${player.monitorOutput}`);

		if (enable) {

			// Special case if output destination is not selectable, e.g. Safari
			if (!player.monitorOutput) {

				const ctx = this.getAudioCtx();
				if (!player.monitor) {
					// await player.pause();
					player.monitor = ctx.createGain();
					player.source.connect(player.monitor);
					player.monitor.connect(ctx.destination);
					// player.play();
				}
				player.monitor.gain.setValueAtTime(1.0, ctx.currentTime + 0.25);
				return;
			}

			// Player must be configured as a WebAudio source
			if (!('source' in player)) {
				this.configurePlayer(player);

				// Create a Audio() object to route output
				// to the player's original sinkId
				player.output = new Audio();
				player.output.srcObject = player.stream;
				await player.output.setSinkId(player.sinkId);
				player.output.play();
			}

			if (!player.monitor) {
				// Create a Audio() object to route output
				// to the selected monitor output, if possible.
				// Use default destination if output selection
				// isn't possible.
				player.monitor = new Audio();
				player.monitor.srcObject = player.stream;
				const destId = player.monitorOutput.getValue();
				await player.monitor.setSinkId(destId);
			}

			player.monitor.play();

		} else {

window.xPlayer = player;

			// Shortcut if output destination is not selectable
			if (!player.monitorOutput) {
				if (player.monitor instanceof GainNode)
					player.monitor.gain.exponentialRampToValueAtTime(0.01, player.monitor.context.currentTime + 0.25)
				return;
			}

			// Turn off monitoring if enabled.  Once player output has been re-routed to
			// a MediaElementSource, it can't be un-routed.  So, we simply stop (pause)
			// and destroy the monitor player object.
			if (player.monitor) {
				player.monitor.pause();
				player.monitor = null;
			}
		}
	}

	// Configure a <select> element to serve as the input or output selector for a media element,
	// based on the environment configuration as determined by init.
	configureSelector(selectorDiv, player, kind = 'audiooutput') {
		if (!this.selectList) throw new Error("audioUI class not initialized.  Call init()");

		// selector could be a div containing a label, etc., as well as the <select> control.
		let selector;
		if (selectorDiv instanceof HTMLSelectElement)
			selector = selectorDiv
		else
			selector = selectorDiv.querySelector("select");

		// Wire up function for retrieving value
		selectorDiv.getValue = function () { return selector.value; };

		// Configure selector
		selectorDiv.setAttribute('kind', kind);
		selector.options.length = 0; // Get rid of any existing options in selector
		const list = this.selectList[kind];

		if (('audiooutput' == kind) && !this.sourceSelectionEnabled) {

			// Device selection is not enabled, e.g. Safari
			//selectorDiv.hidden = true;
			const option = document.createElement('option');
			option.value = "";
			option.text = this.DEFAULT_NAME[kind];
			selector.appendChild(option);
			selector.disabled = true;

		} else if (list.length && ("" != list[0].value)) {
			// Device selection is enabled, and a choice of devices exists

			// Get previous default, if any, from cookie
			let defaultDest = 'default';
			try {
				defaultDest = document.cookie
					.split('; ')
					.find(row => row.startsWith(selectorDiv.id))
					.split('=')[1];
			} catch {}

			// Populate select list, taking previous selection into account.
			list.forEach(child => {
				const c = child.cloneNode(true);
				if (c.value == defaultDest) c.selected = true;
				selector.appendChild(c);
			});

			// Wire up handler for selecting a new destination
			selector.addEventListener('change', async function (e) {

				// Save last-used value
				document.cookie = `${selectorDiv.id}=${e.target.value};path=/`;

				// If this selector controls a player and it is set up for monitoring,
				// manipulate the player's output object.  If not, just manipulate the player.
				if (player) {
					if (player.monitor)
						await player.output.setSinkId(e.target.value);
					else
						await player.setSinkId(e.target.value);
				}
			});

			// If selected device (net of cookie) isn't the default,
			// switch to it now.
			if (('default' != defaultDest) && ('default' != selector.value))
				selector.dispatchEvent(new Event('change'));

			// Enable UI
			selectorDiv.hidden = false;

		} else {
			// Output device selection capability may exist, but is not enabled.
			// Wire up an event handler to try enabling it when the user first
			// accesses the dropdown

			const option = document.createElement('option');
			option.value = "";
			option.text = this.DEFAULT_NAME[kind];
			selector.appendChild(option);

			// Set up for reconfiguration
			selector.container = selectorDiv;
			if (player) selector.container.player = player;
			selector.onfocusin = this.reconfigure;
			selectorDiv.hidden = false;
		}
	}

	// Run a re-configuration process for an output selector in response to an
	// event (typically focusin) by calling getUserMedia to attempt to unlock
	// access to more media devices.
	async reconfigure(e) {

		audioUI.consumeEvent(e);

		await UIkit.modal.alert(
			`<div class="uk-modal-body">
				<b>Please allow access to the microphone</b>
				<p>Your browser will prompt you to allow access to your
				computer's microphone after you click "OK" on this page.  Please
				respond with "allow" to enable output source selection.
				</p>
				<p class="uk-text-meta">ErosWeb "solo" mode does not actually use the microphone.
				However, all the discrete audio devices on your system –
				including output devices like speakers and headsets –
				are bundled together with the microphone for security purposes.
				Granting access to the microphone enables ErosWeb to use those
				additional output devices.
				</p>
				<p class="uk-text-meta"><b>If you do not see a dialog</b>, you may have accidentally
				blocked access to the microphone already.  Go to the security settings in
				your browser (in Google Chrome, this is
				<code>chrome://settings/content/microphone</code>) and reset
				permissions for the site "<code>${document.location.origin}</code>".
				</div>`, { stack: true }
		);
		try {

			const selectorDiv = e.target.container;
			const player = selectorDiv.player;
			const kind = selectorDiv.getAttribute('kind');

			const constraints = {};
			if ('videoinput' == kind) constraints.video = true;
			if (['audiooutput', 'audioinput'].includes(kind)) constraints.audio = true;

			// Calling "getUserMedia" prompts the user to unlock access to more devices
			const stream = await navigator.mediaDevices.getUserMedia(constraints);

			// We only do this because we never want to use the streams returned by
			// this gUM call again; this call was only to enumerate devices.
			if (stream) stream.getTracks().forEach(track => { track.stop(); });

			// Re-initialize; hopefully read a list of devices & re-configure
			await this.init();

			// Reconfigure this and all active selectors of the same kind (audio* or video*)
			for (const selector of document.querySelectorAll(`*[kind^=${kind.substr(0,5)}] select`)) {
				if (selector.disabled) continue;
				selector.onfocusin = null;
				const targetKind = selector.container.getAttribute('kind');
				this.configureSelector(selector.container, selector.container.player, targetKind);
				delete selector.container; // Temporary property no longer needed.
			}

		} catch (err) {
			// This means that the user did not allow us access to media devices.
			// Just ignore that error.
			if ('Permission denied' != err.message) throw err;
		}
	}

	// Make an event go away.  This needs to be a separate, static function
	// so it can be attached to the window object.
	static consumeEvent(e) {
		e.stopPropagation();
		e.preventDefault();
	}

	// Enable drag-and-drop support for local audioStim files;
	// call this from DOMContentLoaded event handler.
	static configureDropTarget(target, player) {

		// Prevent the default behavior for window drops
		window.addEventListener('dragleave', audioUI.consumeEvent, false);
		window.addEventListener('dragover', audioUI.consumeEvent, false);
		window.addEventListener('drop', audioUI.consumeEvent, false);

		// Configure drop target
		target.addEventListener('dragenter', audioUI.consumeEvent, false);
		target.addEventListener('dragover', e => {
			audioUI.consumeEvent(e);
			e.dataTransfer.dropEffect = 'copy';
			target.classList.add('uk-dragover');
		}, false);
		target.addEventListener('dragleave', e => {
			audioUI.consumeEvent(e);
			target.classList.remove('uk-dragover');
		}, false);
		target.addEventListener('drop', e => {
			audioUI.consumeEvent(e);
			const transfer = e.dataTransfer;
			if (!transfer || !transfer.files || (1 != transfer.files.length)) {
				e.dataTransfer.dropEffect = 'none';
				return;
			}
			this.loadFile(transfer.files, player);
			target.classList.remove('uk-dragover');
			return false;
		}, false);

		// Enable manual file selection via an <input type="file"> element
		const fileUpload = target.querySelector('input[type="file"]');
		if (fileUpload) {
			fileUpload.addEventListener('change', e => {
				audioUI.consumeEvent(e);
				if (e.target.files) this.loadFile(e.target.files, player);
				e.target.value = '';
			}, false);
		}

		// Configure basic player controls
		const ckLoop = target.querySelector('input[type="checkbox"].loop');
		if (ckLoop) {
			ckLoop.checked = player.loop;
			ckLoop.addEventListener('change', () => { player.loop = ckLoop.checked; });
		}

		const ckAutoplay = target.querySelector('input[type="checkbox"].autoplay');
		if (ckAutoplay) {
			ckAutoplay.checked = player.autoplay;
			ckAutoplay.addEventListener('change', () => { player.autoplay = ckAutoplay.checked; });
		}
	}

	// Internal method; load an audio file into the player
	static loadFile(file, player) {
		if (file instanceof FileList) file = file[0];
		if ('' != player.canPlayType(file.type)) {
			player.title = file.name;
			player.src = URL.createObjectURL(file);
		} else {
			let msg = file.type;
			msg = ('' == msg) ? "unknown type" : `type "${msg}"`;
			UIkit.notification(
				`<p class="uk-text-small">Cannot play file of ${msg}.  (${file.name})</p>`, { pos: 'bottom-center', status: 'warning' }
			);
		}
	}

	// Generate test tone in the selected output device
	async testTone(deviceId, atEnd) {

		const oscillator = this.getAudioCtx().createOscillator();
		const lfo = this.getAudioCtx().createOscillator();
		lfo.frequency.value = 2.0; // 2Hz: two oscillations per second

		// create a gain whose gain AudioParam will be controlled by the LFO
		const gain = this.getAudioCtx().createGain();

		// connect the LFO to the gain AudioParam. This means the value of the LFO
		// will not produce any audio, but will change the value of the gain instead
		lfo.connect(gain.gain);
		oscillator.connect(gain);

		if (this.sourceSelectionEnabled) {
			// Get the output of the audio graph as a stream
			const dest = this.getAudioCtx().createMediaStreamDestination();
			gain.connect(dest);

			// Connect the stream to an Audio() object which we can set
			// the destination of and play.
			const player = new Audio();
			player.srcObject = dest.stream;
			await player.setSinkId(deviceId);
			player.play();
		} else {
			// Output device selection isn't possible (Safari)
			gain.connect(this.getAudioCtx().destination);
		}

		oscillator.start();
		lfo.start();

		// Turn the player off after 2.5 seconds
		if (atEnd) oscillator.onended = atEnd;
		oscillator.stop(this.getAudioCtx().currentTime + 2.5);
	}

	// Measure input level from the indicated stream and update the .value property of the uiElement
	testLevel(stream, uiElement) {

		const analyser = this.getAudioCtx().createAnalyser();
		analyser.smoothingTimeConstant = 0.8;
		analyser.fftSize = 1024;

		const microphone = this.getAudioCtx().createMediaStreamSource(stream);

		// TODO: deprecated; port this to use an AudioWorklet...
		const javascriptNode = this.getAudioCtx().createScriptProcessor(2048, 1, 1);

		microphone.connect(analyser);
		analyser.connect(javascriptNode);
		javascriptNode.connect(this.getAudioCtx().destination); // OK because the node never outputs

		javascriptNode.onaudioprocess = function () {
			const array = new Uint8Array(analyser.frequencyBinCount);
			analyser.getByteFrequencyData(array);
			const values = array.reduce((t, c) => t + c, 0);
			uiElement.value = values / array.length;
		}

		stream.getTracks()[0].onended = (e) => {
			microphone.disconnect(analyser);
			analyser.disconnect(javascriptNode);
			javascriptNode.disconnect(this.getAudioCtx().destination);
		};
	}
}

export { audioUI };
